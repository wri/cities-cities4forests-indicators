{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d7677-144c-4df5-961f-352673f7c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap\n",
    "# !{sys.executable} -m pip install pip rasterstats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f259e-62a6-4b7e-b879-8628b18a8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73901903-5245-4507-950b-3a78b2e820b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69f1a8-e7fa-40ac-81db-f9a67f1e82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import io\n",
    "from rasterstats import zonal_stats\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "import geemap\n",
    "import glob\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de7d4d-ed34-493b-8573-ab00825ca668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea530a-3c18-423a-a28a-de82cfa137ff",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330baf82-21ca-423c-803a-37782d5d7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-cities4forests'\n",
    "# bucket_name = 'cities-urbanshift' \n",
    "aws_s3_dir = 'https://'+bucket_name+'.s3.eu-west-3.amazonaws.com/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc57ad-cd50-49e5-9f26-36d20f50f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add Land use land cover dataset\n",
    "WC = ee.ImageCollection(\"ESA/WorldCover/v100\")\n",
    "WorldCover = WC.first();\n",
    "builtup = WorldCover.eq(50)\n",
    "\n",
    "## define projection for use later\n",
    "WCprojection = WC.first().projection();  \n",
    "esaScale = WorldCover.projection().nominalScale();  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565931a6-b956-45af-a57b-76038e435b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read Trees in Mosaic Landscapes tree cover dataset\n",
    "TML = ee.ImageCollection('projects/wri-datalab/TML')\n",
    "TreeCoverImg = TML.reduce(ee.Reducer.mean()).rename('b1')\n",
    "TreeCovergt0 = TreeCoverImg.updateMask(TreeCoverImg.gt(0))\n",
    "\n",
    "# # select only pixels with 10% or greater tree cover\n",
    "# TreePctThreshold = 10 #whole numbers - 0-100\n",
    "# TreeCover = TreeCover.updateMask(TreeCover.gte(TreePctThreshold))\n",
    "\n",
    "# ## Reproject trees to match LULC projection\n",
    "# TreeCover = TreeCover.reproject(crs= WCprojection)\n",
    "\n",
    "# https://gis.stackexchange.com/questions/421422/google-earth-engine-image-no-data-mask\n",
    "TreeDataMask = TreeCoverImg.unmask(-99).neq(-99)   # give no data pixels an abitrary value outside the range of the data. Then make a boolean raster using the assigned value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e383b5-6e86-4cf9-8490-7cf2c8262c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create layer with tree cover in builtup areas\n",
    "builtupTreeCover = TreeCovergt0.updateMask(builtup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa5ee9-8643-433d-9275-0fbc3ba0230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of c4f cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir +'/boundaries/v_0/boundary_georef.csv')\n",
    "# boundary_georef = pd.read_csv(aws_s3_dir +'/boundaries/AUE/boundary_georef_AUE.csv')\n",
    "\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1c571-5f1e-4a24-8dd7-9222ffe1097a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155f1c4-4efe-4b67-916f-29090041d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicatorDF = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14284f35-bc11-42aa-8661-a7be87c63366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define calcuation function to get pixel counts, convert to percents and append to data frame\n",
    "def CountCalcsDF(FC,DF):\n",
    "    \n",
    "    # reduce images to get vegetation and built-up pixel counts\n",
    "    pixelcounts = builtupTreeCover.reduceRegions(FC,ee.Reducer.count().setOutputs(['TreeBuiltPixels']),esaScale) # larger scale (50+) required for large cities to avoid EE memory issues\n",
    "    pixelcounts = builtup.reduceRegions(pixelcounts,ee.Reducer.count().setOutputs(['BuiltPixels']),esaScale) # larger scale (50+) required for large cities to avoid EE memory issues\n",
    "    pixelcounts = TreeDataMask.reduceRegions(pixelcounts,ee.Reducer.anyNonZero().setOutputs(['TreeDataAvailable']),esaScale)\n",
    "    pixelcounts = TreeCoverImg.reduceRegions(pixelcounts,ee.Reducer.mean().setOutputs(['TreeCoverMean']),esaScale)\n",
    "\n",
    "    # convert pixel counts to area percentages and saves to FC as property\n",
    "    def toPct(feat):\n",
    "        BuiltpctEq = ee.Number(1).subtract((feat.getNumber('TreeBuiltPixels')).divide(feat.getNumber('BuiltPixels')))\n",
    "        Builtpct = ee.Algorithms.If(feat.getNumber('TreeDataAvailable').eq(0),\"NA\",BuiltpctEq)\n",
    "        Treepct = ee.Algorithms.If(feat.getNumber('TreeDataAvailable').eq(0),\"NA\",(feat.getNumber('TreeCoverMean').multiply(0.01)))\n",
    "        return feat.set({\n",
    "            'PctBuiltwoTree': Builtpct,\n",
    "            'PctTreeCover': Treepct\n",
    "      })\n",
    "\n",
    "    pixelcounts = pixelcounts.map(toPct).select(['geo_id','PctBuiltwoTree','PctTreeCover'])\n",
    "\n",
    "    # store in df and append\n",
    "    df = geemap.ee_to_pandas(pixelcounts)\n",
    "    df = df.rename(columns={'PctBuiltwoTree': 'GRE_1_4_percentBuiltupWithoutTreeCover'})\n",
    "    DF = DF.append(df)\n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1321258-b74e-4446-be81-ed7c2423d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1): #,len(boundary_georef)):\n",
    "# for i in list(range(0, 56)) + list(range(57,120)) + list(range(121,131)) + list(range(132,len(boundary_georef))):\n",
    "# for i in list(range(111,120)) + list(range(121,131)) + list(range(132,len(boundary_georef))):\n",
    "\n",
    "    print(i)\n",
    "    geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "    print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "    # process aoi level ------\n",
    "    boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    print(\"\\n boundary_id_aoi: \"+boundary_id_aoi)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/boundaries/v_0/boundary-'+boundary_id_aoi+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = ee.FeatureCollection(boundary_geo)\n",
    "    \n",
    "    this_indicatorDF = CountCalcsDF(boundary_geo_ee, this_indicatorDF)\n",
    "\n",
    "    \n",
    "    # process unit of analysis level ------\n",
    "    boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "    print(\"\\n boundary_id_unit: \"+boundary_id_unit)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir +'/boundaries/v_0/boundary-'+boundary_id_unit+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    # boundary_geo_ee = ee.FeatureCollection(boundary_geo)\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    this_indicatorDF = CountCalcsDF(boundary_geo_ee, this_indicatorDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e36d60-52d1-4a98-bbed-6271e2a20c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicatorDF#.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe3aa9-ccdc-4e6c-880e-a6226532ef8b",
   "metadata": {},
   "source": [
    "# Workaround for timeout problems for specific geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baeb38c-6ac9-4ce5-9edc-af78b87c8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if timeout problems for a ingesting a geography (\"EEException: Request payload size exceeds the limit\") or computing indicator (\"Exception: Computation timed out\"), save boundary as ee.FeatureCollection as EE asset in EE Code Editor then reference assets directly, one at a time.\n",
    "\n",
    "# boundary_geo_ee = ee.FeatureCollection('users/emackres/AUE/boundary-USA-New_York-AUEt3')\n",
    "# boundary_geo_ee = ee.FeatureCollection('users/emackres/AUE/boundary-CHN-Guangzhou_Guangdong-AUEt3')\n",
    "# boundary_geo_ee = ee.FeatureCollection('users/emackres/AUE/boundary-FRA-Paris-AUEt3')\n",
    "# boundary_geo_ee = ee.FeatureCollection('users/emackres/AUE/boundary-USA-Chicago-AUEt3')\n",
    "\n",
    "# this_indicatorDF = CountCalcsDF(boundary_geo_ee, this_indicatorDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf3731-4d7d-43a1-a662-75bde29065c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicatorDF#.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5abd9b-097c-4676-a500-ecd45ad77374",
   "metadata": {},
   "source": [
    "# Merge with indicator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fba45-59b3-44fe-94a9-3520763dffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read indicator table\n",
    "cities_indicators = pd.read_csv(aws_s3_dir + '/indicators/cities_indicators_v2test.csv') \n",
    "# cities_indicators = pd.read_csv(aws_s3_dir + '/indicators/cities_indicators_AUE.csv') \n",
    "cities_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978df631-317b-4c42-8c8a-d8ee108e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_indicators(indicator_table, new_indicator_table, indicator_name):\n",
    "    if indicator_name in indicator_table.columns:\n",
    "        print(\"replace with new calculations\")\n",
    "        indicator_table.drop(indicator_name, inplace=True, axis=1)\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    else:\n",
    "        print(\"add new indicators\")\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    return(cities_indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa73a3a-ea72-42ab-81ed-589b95ef33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators,\n",
    "                                            new_indicator_table = this_indicatorDF,\n",
    "                                            indicator_name = \"GRE_1_4_percentBuiltupWithoutTreeCover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47025947-7f5b-4e85-91ca-91e09aedb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators_merged,\n",
    "                                            new_indicator_table = this_indicatorDF,\n",
    "                                            indicator_name = 'PctTreeCover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10c1e2-9aa9-4d43-a110-8550e4f36e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba258d2-9e13-4fcc-bf22-4aeb3f359405",
   "metadata": {},
   "source": [
    "# Upload in aws s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c059a57-b6a6-4354-b24b-f45102ec8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "# aws_credentials = pd.read_csv('C:\\\\Users\\\\Saif.Shabou\\\\OneDrive - World Resources Institute\\\\Documents\\\\aws\\\\credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2235f8-fb77-40f6-91d8-908dca3fd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to aws\n",
    "key_data = 'data/indicators/cities_indicators_v2test.csv'\n",
    "# key_data = 'data/indicators/cities_indicators_AUE.csv'\n",
    "\n",
    "cities_indicators_merged.to_csv(\n",
    "    f\"s3://{bucket_name}/{key_data}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": aws_key,\n",
    "        \"secret\": aws_secret\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ed391-015d-4778-acc5-37c0c7a04703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it public\n",
    "object_acl = s3.ObjectAcl(bucket_name,key_data)\n",
    "response = object_acl.put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf202dd-5adf-44d6-83b2-bcba1e8e3d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
